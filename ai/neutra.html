<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>文字認識AI</title>
    <style>
        /* 全体のスタイル */
        body {
            font-family: Arial, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            margin: 0;
        }

        /* キャンバスのスタイル */
        #canvas {
            border: 2px solid #000;
            cursor: crosshair;
        }

        /* 認識ボタンのスタイル */
        #recognizeBtn {
            margin-top: 10px;
            padding: 10px 20px;
            background-color: #4CAF50;
            color: white;
            border: none;
            cursor: pointer;
        }

        /* 結果表示用のスタイル */
        #result {
            margin-top: 20px;
            font-size: 1.5em;
        }
    </style>
</head>
<body>

    <h1>手書き文字認識</h1>

    <!-- キャンバスの作成 -->
    <canvas id="canvas" width="200" height="200"></canvas>
    <button id="recognizeBtn">認識</button>

    <!-- 認識結果表示用 -->
    <div id="result">ここに結果が表示されます</div>

    <script src="https://cdn.jsdelivr.net/npm/convnetjs"></script>
    <script>
        // キャンバスとそのコンテキストを取得
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        let drawing = false;

        // ユーザーが描き始めたときの処理
        canvas.addEventListener('mousedown', () => {
            drawing = true;
            ctx.beginPath();
        });

        // ユーザーが描いている間の処理
        canvas.addEventListener('mousemove', (e) => {
            if (drawing) {
                const rect = canvas.getBoundingClientRect();
                const x = e.clientX - rect.left;
                const y = e.clientY - rect.top;
                ctx.lineWidth = 10;
                ctx.lineCap = 'round';
                ctx.strokeStyle = '#000';
                ctx.lineTo(x, y);
                ctx.stroke();
            }
        });

        // ユーザーが描き終わったときの処理
        canvas.addEventListener('mouseup', () => {
            drawing = false;
        });

        // ConvNet.jsのネットワーク設定
        const layer_defs = [];
        layer_defs.push({type: 'input', out_sx: 24, out_sy: 24, out_depth: 1});
        layer_defs.push({type: 'conv', sx: 5, filters: 8, stride: 1, pad: 2, activation: 'relu'});
        layer_defs.push({type: 'pool', sx: 2, stride: 2});
        layer_defs.push({type: 'conv', sx: 5, filters: 16, stride: 1, pad: 2, activation: 'relu'});
        layer_defs.push({type: 'pool', sx: 3, stride: 3});
        layer_defs.push({type: 'softmax', num_classes: 10});

        // ネットワークの作成
        const net = new convnetjs.Net();
        net.makeLayers(layer_defs);

        // トレーナーの設定
        const trainer = new convnetjs.SGDTrainer(net, {method: 'adadelta', batch_size: 20, l2_decay: 0.001});

        // 画像データをキャンバスから取得し、24x24のグレースケールデータに変換
        function getImageData() {
            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            const grayData = [];

            for (let y = 0; y < 24; y++) {
                for (let x = 0; x < 24; x++) {
                    // 画像のスケーリング
                    const scaledX = Math.floor((x / 24) * canvas.width);
                    const scaledY = Math.floor((y / 24) * canvas.height);
                    const index = (scaledY * canvas.width + scaledX) * 4;
                    const r = imageData.data[index];
                    const g = imageData.data[index + 1];
                    const b = imageData.data[index + 2];
                    const gray = (r + g + b) / 3; // グレースケールに変換
                    grayData.push(gray / 255.0); // 0から1の範囲に正規化
                }
            }

            // グレースケールデータをVolに変換
            const vol = new convnetjs.Vol(24, 24, 1, 0.0);
            for (let i = 0; i < grayData.length; i++) {
                vol.set(i % 24, Math.floor(i / 24), 0, grayData[i]);
            }

            return vol;
        }

        // 認識ボタンが押されたときの処理
        document.getElementById('recognizeBtn').addEventListener('click', () => {
            const inputVol = getImageData();
            const prediction = net.forward(inputVol);
            const predictedClass = prediction.w.indexOf(Math.max(...prediction.w));

            // 結果を表示
            document.getElementById('result').textContent = `認識された数字: ${predictedClass}`;
        });

        // キャンバスのリセット
        document.getElementById('clearBtn').addEventListener('click', () => {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            document.getElementById('result').textContent = 'ここに結果が表示されます';
        });
    </script>
</body>
</html>
